{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.stats.api as sms\n",
    "#import statsmodels.formula.api as smf\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. scatter_matrix to examine how features and label are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.scatter_matrix(df, figsize=(8, 5), s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Explore features\n",
    "**Pay attention to Timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_train_all['YearMade'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make pandas show all colums\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef check_zero(df, col):\\n    if sum(df[col]==0)>0:\\n        print 'Column', col,':',sum(df[col]==0),'rows are 0'\\n    else:\\n        print 'No 0 values in column {}'.format(col)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if there is any null/NaN in a column\n",
    "# sum(df_train_all['MachineHoursCurrentMeter'].isnull())\n",
    "\n",
    "'''\n",
    "def check_nan(df, cols):\n",
    "    print 'Dataframe total row count: ', df.shape[0]\n",
    "    nan_cnt = 0\n",
    "    for c in cols:\n",
    "        if sum(df[c].isnull())>0:\n",
    "            print c , ' has ' , sum(df[c].isnull()) , 'null/NAN values'\n",
    "            nan_cnt += 1\n",
    "    print 'There are {} columns with nan/null values'.format(nan_cnt)\n",
    "    return None\n",
    "'''\n",
    "## Check if there is any 0 in a column\n",
    "'''\n",
    "def check_zero(df, col):\n",
    "    if sum(df[col]==0)>0:\n",
    "        print 'Column', col,':',sum(df[col]==0),'rows are 0'\n",
    "    else:\n",
    "        print 'No 0 values in column {}'.format(col)\n",
    "'''\n",
    "\n",
    "## If NaN is a string in the column\n",
    "# df.replace('NaN', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Check correlation between features\n",
    "# corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before going further, parse year, month, day if necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['year'] =  pd.to_datetime(df['saledate']).dt.year.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Select all numerical features into a new dataframe\n",
    "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "# df_numeric = df.select_dtypes(include=numerics)\n",
    "## Or\n",
    "# df_numeric = df.select_dtypes(exclude=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. convert categorical to 1 and 0\n",
    "### (may need to merge train and test to do it together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_1 = pd.concat([df_1, pd.get_dummies(df_1['Ethnicity'], drop_first=True)], axis=1)\n",
    "## Or\n",
    "# balance['Married'] = balance['Married'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If joining two different sized data frame is necessary\n",
    "# pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NanN/null value fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the bad rows are not that many, just drop them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop rows that have any NaN\n",
    "# df_new = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop rows based on condition:\n",
    "# cond = df['YearMade']<1960\n",
    "# df.drop(df[cond].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop rows if certain column is NaN\n",
    "# cond = df['colname'].isnull()\n",
    "# df.drop(df[cond].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Falling NaN or 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For categorical, if NaN is too many, try to fill with the most common value\n",
    "## See which one is the most commom\n",
    "# df.groupby(['col'])['col'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncond1 = df['column'].notnull()\\ncond2 = df['column']!=0\\ndf[cond1&cond2]['column'].describe()\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For numerical\n",
    "'''\n",
    "cond1 = df['column'].notnull()\n",
    "cond2 = df['column']!=0\n",
    "df[cond1&cond2]['column'].describe()\n",
    "'''\n",
    "\n",
    "## Plot histogram for numeric column without NAN\n",
    "# cond1 = df['column'].notnull()\n",
    "# cond2 = df['column']!=0\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(df[cond1&cond2]['column'], bins=5)\n",
    "#fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fillna\n",
    "# df['colname']=df['colname'].fillna(<val>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Replace certain values\n",
    "# cond = df_test['col']==bad_value\n",
    "# df.loc[cond, 'col'] = new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imbalanced class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.*sum(y==1)/len(y)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler, RandomUnderSampler\n",
    "# ros = RandomOverSampler()\n",
    "# X_resampled, y_resampled = ros.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic model with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## It's helpful to create a mean column as the baseline\n",
    "# y_mean = np.empty(len(y_test))\n",
    "# y_mean.fill(y_test.values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set up X and y\n",
    "# X = df[['colname1','colname2']]\n",
    "## Or\n",
    "# X = df[df.drop('y_colname', axis =1).columns]\n",
    "# y = df['colnam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split train test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalphas = np.linspace(100, 200, 500)\\nmses = []\\nfor a in alphas:\\n    clf = Lasso(alpha=a)\\n    clf.fit(X_train_scale, y_train)\\n    y_pred = clf.predict(X_test_scale)\\n    mse = sklearn.metrics.mean_squared_error(y_test, y_pred)\\n    mses.append(mse)\\n\\nplt.plot(alphas, mses)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use certain metrics to get a basic idea of how it's doing\n",
    "## Regression:\n",
    "# sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "## Create a Lasso curve\n",
    "'''\n",
    "alphas = np.linspace(100, 200, 500)\n",
    "mses = []\n",
    "for a in alphas:\n",
    "    clf = Lasso(alpha=a)\n",
    "    clf.fit(X_train_scale, y_train)\n",
    "    y_pred = clf.predict(X_test_scale)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
    "    mses.append(mse)\n",
    "\n",
    "plt.plot(alphas, mses)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Computer R square\n",
    "# from sklearn.metrics import r2_score\n",
    "# r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To check linear-ness of the data captured by the model:\n",
    "# linear_model = sm.OLS(prestige['education'], sm.add_constant(prestige['prestige']))\n",
    "# linear_model = linear_model_card.fit()\n",
    "# linear_model.summary()\n",
    "# residual = linear_model.outlier_test()['student_resid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the residual plot shows non-linear, model needs to be optimized, either use non-linear model, or add features, or transform variables to increase linearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For regression, check label distribution\n",
    "## If uneven, try log transform\n",
    "## Or other non-linear transformations: http://stattrek.com/regression/linear-transformation.aspx?Tutorial=AP\n",
    "## After log transform, regulization may not be needed\n",
    "\n",
    "# y_train_log = y_train.apply(np.log)\n",
    "\n",
    "\n",
    "## After transformation, residual plot is necessary to evaluate imporvement\n",
    "# linear_model = sm.OLS(prestige['education'], sm.add_constant(prestige['prestige']))\n",
    "# linear_model = linear_model_card.fit()\n",
    "# linear_model.summary()\n",
    "# residual = linear_model.outlier_test()['student_resid']\n",
    "\n",
    "## After transformation, R square is also needed\n",
    "# r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# recall_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\') / cm.sum(axis=1)[:, np.newaxis]\\n        print(\"Normalized confusion matrix\")\\n    else:\\n        print(\\'Confusion matrix, without normalization\\')\\n\\n    print(cm)\\n\\n    plt.imshow(cm, interpolation=\\'nearest\\', cmap=cmap)\\n    plt.title(title)\\n    plt.colorbar()\\n    tick_marks = np.arange(len(classes))\\n    plt.xticks(tick_marks, classes, rotation=45)\\n    plt.yticks(tick_marks, classes)\\n\\n    fmt = \\'.2f\\' if normalize else \\'d\\'\\n    thresh = cm.max() / 2.\\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\\n        plt.text(j, i, format(cm[i, j], fmt),\\n                 horizontalalignment=\"center\",\\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\\n\\n    plt.tight_layout()\\n    plt.ylabel(\\'True label\\')\\n    plt.xlabel(\\'Predicted label\\')\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Plot a pretty confusion matrix\n",
    "'''\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "'''\n",
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# plot_confusion_matrix(cnf_matrix\n",
    "#                       , classes=class_names\n",
    "#                       , title='Confusion matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Tree-based model/Feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(X, y)\n",
    "# feature_names = X.columns\n",
    "# y_pred = clf.predict(X)\n",
    "# cross_val_score(clf, X, y, cv = 11, scoring = 'roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimportances = clf.feature_importances_\\nindices = np.argsort(importances)[::-1]\\nfeature_names = list(X_train.columns[indices])\\nprint importances[indices]\\nplt.title(\"Feature importances\")\\nplt.bar(range(9), importances[indices], color=\"r\", align=\"center\")\\nplt.xticks(range(9), feature_names)\\nplt.xlim([-1, 10])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print feature importance\n",
    "# importances = clf.feature_importances_\n",
    "# important_names = feature_names[importances > np.mean(importances)]\n",
    "# print important_names\n",
    "\n",
    "## Or to show all:\n",
    "# [(name, imp) for name, imp in zip(feature_names, importances)]\n",
    "\n",
    "## Or plot bar chart:\n",
    "'''\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = list(X_train.columns[indices])\n",
    "print importances[indices]\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(9), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(9), feature_names)\n",
    "plt.xlim([-1, 10])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## XGBOOST\n",
    "# import xgboost as xgb\n",
    "# gbm = xgb.XGBClassifier(max_depth=3, n_estimators=1000, learning_rate=0.001)\n",
    "# cross_val_score(gbm, X, y, cv = 11, scoring = 'accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. examine the linear regression assumptions:\n",
    "### 1) Homoscedasticity of residuals\n",
    "**Use studentized residual vs y_hat to plot and eyeball:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#std_residual = (y-y_pred)/np.std((y_pred-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or use statsmodel, the Goldfeld-Quandt test evaluates the p-value under the null of homoscedasticity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear_model = sm.OLS(prestige['education'], sm.add_constant(prestige['prestige']))\n",
    "# linear_model = linear_model_card.fit()\n",
    "# linear_model.summary()\n",
    "# residual = linear_model.outlier_test()['student_resid']\n",
    "# test = sms.het_goldfeldquandt(linear_model.resid, linear_model.model.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(y_hat, student_resid)\n",
    "# plt.xlabel('Fitted values of y')\n",
    "# plt.ylabel('Studentized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Normal distribution of residuals\n",
    "**So that we can get the least squared betas**\n",
    "\n",
    "**Use Q-Q plot: The Q-Q plot plots the quantile of the normal distribution\n",
    "against that of the studentized residuals and checks for alignment of the\n",
    "quantiles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sm.graphics.qqplot(residual, line='45', fit=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Lack of multicollinearity among features\n",
    "** when checking the scatter_matrix, highly correlated features shows as a near-line\n",
    "pattern**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use statsmodel summary:**\n",
    "\n",
    "**Condition Number (included in model summary). As a rule of thumb, a\n",
    "condition number > 30 indicates multicollinearity between the features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or**\n",
    "\n",
    "** Use VIF:**\n",
    "\n",
    "**As a rule of thumb, a VIF > 10 indicates the feature is collinear with at\n",
    "least one other feature.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variance_inflation_factor(X1.values, 0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## variance_inflation_factor takes a matrix of features (numpy matrix, not pandas dataframe) and the column \n",
    "## index of the feature the VIF is to be calculated\n",
    "\n",
    "# variance_inflation_factor(X1.values, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Independence of the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Also use the studentized residual plot\n",
    "# plt.scatter(y_hat, student_resid)\n",
    "# plt.xlabel('Fitted values of y')\n",
    "# plt.ylabel('Studentized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) No high-leverage data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross Validation\n",
    "**Check the list of scoring options:**\n",
    "*http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn always return a negative score.\n",
    "The actual MSE is simply the positive version of the number you're getting.**\n",
    "\n",
    "**The unified scoring API always maximizes the score, so scores which need to be minimized are negated in order for the unified scoring API to work correctly. The score that is returned is therefore negated when it is a score that should be minimized and left positive if it is a score that should be maximized.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Linear regression\n",
    "# lasso = linear_model.Lasso(alpha=a, normalize=True)\n",
    "# print(cross_val_score(lasso, X, y, cv = 5, scoring = 'mean_squared_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## More controlled cross validation\n",
    "# seed = 7\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(model, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "# clf = LogisticRegression()\n",
    "# cross_val_score(clf, X, y, cv = 11, scoring = 'roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "# clf = RandomForestClassifier()\n",
    "# cross_val_score(clf, X, y, cv = 11, scoring = 'roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrandom_forest_grid = {'max_depth': [3, None],\\n                      'max_features': ['sqrt', 'log2', None],\\n                      'min_samples_split': [2, 4],\\n                      'min_samples_leaf': [1, 2, 4],\\n                      'bootstrap': [True, False],\\n                      'n_estimators': [100],\\n                      'random_state': [1]}\\nrf_gridsearch = GridSearchCV(RandomForestClassifier(),\\n                             random_forest_grid,\\n                             n_jobs=-1,\\n                             verbose=True,\\n                             scoring='roc_auc')\\nrf_gridsearch.fit(X_train, y_train)\\n\\n\\n\\n\\nbest_rf_model = rf_gridsearch.best_estimator_\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search CV for Random Forest\n",
    "'''\n",
    "random_forest_grid = {'max_depth': [3, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True, False],\n",
    "                      'n_estimators': [100],\n",
    "                      'random_state': [1]}\n",
    "rf_gridsearch = GridSearchCV(RandomForestClassifier(),\n",
    "                             random_forest_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='roc_auc')\n",
    "rf_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_rf_model = rf_gridsearch.best_estimator_\n",
    "'''\n",
    "# y_pred = best_rf_model.predict(X_train)\n",
    "# recall_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngradient_boosting_grid = {\\'learning_rate\\': [0.1, 0.05, 0.02, 0.01],\\n                          \\'max_depth\\': [2, 4, 6],\\n                          \\'min_samples_leaf\\': [1, 2, 5, 10],\\n                          \\'max_features\\': [1.0, 0.3, 0.1],\\n                          \\'n_estimators\\': [500],\\n                          \\'random_state\\': [1]}\\ngbr_gridsearch = GridSearchCV(GradientBoostingRegressor(), \\n                              gradient_boosting_grid,\\n                              n_jobs=-1,\\n                              scoring=\\'mean_squared_error\\')\\ngbr_gridsearch.fit(X_train, y_train)\\nprint \"best parameters:\", gbr_gridsearch.best_params_\\n\\nbest_gbr_model = gbr_gridsearch.best_estimator_\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search for GB Regression\n",
    "'''\n",
    "gradient_boosting_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "                          'max_depth': [2, 4, 6],\n",
    "                          'min_samples_leaf': [1, 2, 5, 10],\n",
    "                          'max_features': [1.0, 0.3, 0.1],\n",
    "                          'n_estimators': [500],\n",
    "                          'random_state': [1]}\n",
    "gbr_gridsearch = GridSearchCV(GradientBoostingRegressor(), \n",
    "                              gradient_boosting_grid,\n",
    "                              n_jobs=-1,\n",
    "                              scoring='mean_squared_error')\n",
    "gbr_gridsearch.fit(X_train, y_train)\n",
    "print \"best parameters:\", gbr_gridsearch.best_params_\n",
    "\n",
    "best_gbr_model = gbr_gridsearch.best_estimator_\n",
    "'''\n",
    "# y_pred = best_gbr_model.predict(X_train)\n",
    "# recall_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrees = [300,500]\\nfor t in trees:\\n    clf = GradientBoostingClassifier(n_estimators=t,min_samples_leaf=10,learning_rate=0.02 ,max_depth=4)\\n    print '# of trees:{}, mean accuracy:'.format(t),cross_val_score(clf, X, y, cv = 5, scoring = 'accuracy').mean()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search for GB Classification\n",
    "'''\n",
    "gradient_boosting_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "                          'loss': ['deviance', 'exponential'],\n",
    "                          'max_depth': [2, 4, 6],\n",
    "                          'min_samples_leaf': [1, 2, 5, 10],\n",
    "                          'max_features': [1.0, 0.3, 0.1],\n",
    "                          'n_estimators': [500],\n",
    "                          'random_state': [1]}\n",
    "gbclf_gridsearch = GridSearchCV(GradientBoostingClassifier(), \n",
    "                              gradient_boosting_grid,\n",
    "                              n_jobs=-1,\n",
    "                              scoring='roc_auc')\n",
    "gbclf_gridsearch.fit(X_train, y_train)\n",
    "print \"best parameters:\", gbclf_gridsearch.best_params_\n",
    "\n",
    "best_gbclf_model = gbclf_gridsearch.best_estimator_\n",
    "'''\n",
    "# y_pred = best_gbclf_model.predict(X_train)\n",
    "# recall_score(y_train, y_pred)\n",
    "'''\n",
    "trees = [300,500]\n",
    "for t in trees:\n",
    "    clf = GradientBoostingClassifier(n_estimators=t,min_samples_leaf=10,learning_rate=0.02 ,max_depth=4)\n",
    "    print '# of trees:{}, mean accuracy:'.format(t),cross_val_score(clf, X, y, cv = 5, scoring = 'accuracy').mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble.partial_dependence import plot_partial_dependence\\nnames = X.columns\\n\\nfeatures = [0,1,2,3,4,5,6,7]\\nfig, axs = plot_partial_dependence(best_gbclf_model, X_train, features,\\n                                       feature_names=names,\\n                                       n_jobs=3, grid_resolution=50)\\nfig.set_size_inches(18.5, 10.5, forward=True)\\nplt.subplots_adjust(top=0.9)  # tight_layout causes overlap with suptitle\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Partial dependence:\n",
    "'''\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "names = X.columns\n",
    "\n",
    "features = [0,1,2,3,4,5,6,7]\n",
    "fig, axs = plot_partial_dependence(best_gbclf_model, X_train, features,\n",
    "                                       feature_names=names,\n",
    "                                       n_jobs=3, grid_resolution=50)\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "plt.subplots_adjust(top=0.9)  # tight_layout causes overlap with suptitle\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
